#!/usr/bin/env python3
"""
æ¨¡ç»„ç»´åŸºæ„å»ºå™¨ - CoeHarMod - DEBUG TRANSLATION MATCHING
- æ·»åŠ äº†è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯ï¼Œæ˜¾ç¤ºåŠ è½½çš„ç¿»è¯‘é”®å’ŒæŸ¥æ‰¾çš„é”®
"""

import json
import sys
from pathlib import Path
from urllib.request import urlopen
from typing import Dict, Any, Union

MOD_ROOT = Path(__file__).parent.resolve()
PYTHON_DIR = MOD_ROOT / "python"
JSON_DIR = MOD_ROOT / "jsons"
IMAGES_DIR = MOD_ROOT / "Images"
OUTPUT_DIR = MOD_ROOT / "docs"

# è®¾ç½®è¶…æ—¶æ—¶é—´
DEFAULT_TIMEOUT = 10  # ç§’

BASE_TRANSLATIONS_URL = "https://raw.githubusercontent.com/yairm210/Unciv/master/android/assets/jsons/translations"
LANGUAGES = ["English", "Simplified_Chinese"]


def strip_json_comments(json_str: str) -> str:
    """
    ç§»é™¤ JSON ä¸­çš„ // å’Œ /* */ æ³¨é‡Šï¼Œä¸å½±å“å­—ç¬¦ä¸²å†…å®¹ã€‚
    """
    result = []
    in_string = False
    escape_next = False
    i = 0
    while i < len(json_str):
        c = json_str[i]
        if escape_next:
            escape_next = False
            result.append(c)
        elif c == '\\':
            escape_next = True
            result.append(c)
        elif c == '"':
            in_string = not in_string
            result.append(c)
        elif not in_string and json_str[i:i + 2] == '//':
            # è·³è¿‡ // æ³¨é‡Šç›´åˆ°è¡Œå°¾
            while i < len(json_str) and json_str[i] != '\n':
                i += 1
            continue  # continue å¾ªç¯ï¼Œi å·²ç»æŒ‡å‘ \n
        elif not in_string and json_str[i:i + 2] == '/*':
            # è·³è¿‡ /* */ æ³¨é‡Š
            while i < len(json_str) and json_str[i:i + 2] != '*/':
                i += 1
            i += 2  # è·³è¿‡ */
            continue
        else:
            result.append(c)
        i += 1
    return ''.join(result)


def load_unciv_json(file_path: Path) -> Union[list, dict]:
    """
    åŠ è½½å¯èƒ½å¸¦æœ‰æ³¨é‡Šçš„ Unciv JSON æ–‡ä»¶ã€‚
    """
    with open(file_path, encoding="utf-8-sig") as f:
        content = f.read()
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        pass  # å¿½ç•¥é”™è¯¯ï¼Œå°è¯•å»é™¤æ³¨é‡Š
    clean_content = strip_json_comments(content)
    return json.loads(clean_content)


def download_file(url: str, target: Path, timeout: int = DEFAULT_TIMEOUT):
    """
    ä¸‹è½½æ–‡ä»¶ï¼Œå¸¦è¶…æ—¶å’Œè¿›åº¦åé¦ˆã€‚
    """
    if target.exists():
        print(f"â„¹ï¸  è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰: {target.name}")
        return
    try:
        print(f"â³ æ­£åœ¨ä¸‹è½½ {target.name}...", end='', flush=True)
        with urlopen(url, timeout=timeout) as resp, open(target, 'wb') as f:
            f.write(resp.read())
        print(" âœ…")  # ä¸‹è½½çŠ¶æ€åæ¢è¡Œ
    except Exception as e:
        print(f" âŒ (å¤±è´¥: {e})")
        print(f"âš ï¸  æ— æ³•ä¸‹è½½ {url}ã€‚è¯·ç¡®ä¿ {target} å­˜åœ¨æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚", file=sys.stderr)


def load_properties(file_path: Path) -> Dict[str, str]:
    """
    ä» .properties æ–‡ä»¶åŠ è½½ç¿»è¯‘é”®å€¼å¯¹ã€‚
    """
    trans = {}
    if not file_path.exists():
        print(f"âš ï¸  ç¿»è¯‘æ–‡ä»¶ç¼ºå¤±: {file_path}", file=sys.stderr)
        return trans
    print(f"ğŸ” Loading properties from: {file_path}")  # Debug
    with open(file_path, encoding="utf-8") as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if line and not line.startswith("#") and "=" in line:
                parts = line.split("=", 1)
                if len(parts) >= 2:
                    key = parts[0].strip()
                    value = parts[1].strip().replace("\\n", "\n")
                    trans[key] = value
                    # Debug: Print the first few keys to see examples
                    if len(trans) <= 5:
                        print(f"  ğŸ“Œ Loaded key: '{key}' -> '{value}'")  # Debug
                else:
                    print(f"  âš ï¸  Malformed line {line_num}: '{line}'")  # Debug
    print(f"  Loaded {len(trans)} keys from {file_path.name}")  # Debug
    return trans


def translate_translatable(text: str, trans: Dict[str, str], debug_context: str = "") -> str:
    """
    é«˜æ•ˆåœ°æ¨¡æ‹Ÿ Unciv çš„ Translatable.toRawString() è¡Œä¸ºã€‚
    ä½¿ç”¨åˆ—è¡¨æ‹¼æ¥ä»£æ›¿å­—ç¬¦ä¸²æ‹¼æ¥ï¼Œé¿å…é‡å¤åˆ›å»ºå­—ç¬¦ä¸²å¯¹è±¡ã€‚
    """
    if "[" not in text:
        return text

    result_parts = []
    last_end = 0
    i = 0
    while i < len(text):
        if text[i] == '[':
            # æ‰¾åˆ° [ çš„ä½ç½®
            start = i
            # å¯»æ‰¾åŒ¹é…çš„ ]
            bracket_count = 1
            j = i + 1
            while j < len(text) and bracket_count > 0:
                if text[j] == '[':
                    bracket_count += 1
                elif text[j] == ']':
                    bracket_count -= 1
                j += 1

            if bracket_count == 0:  # æ‰¾åˆ°äº†åŒ¹é…çš„ ]
                # æ·»åŠ  [ ä¹‹å‰çš„å†…å®¹
                result_parts.append(text[last_end:start])
                # æå– [ ] å†…çš„é”®
                key = text[start + 1:j - 1]
                # æŸ¥æ‰¾ç¿»è¯‘
                replacement = trans.get(key, f"[{key}]")
                # Debug: Print every lookup
                print(f"  ğŸ” [{debug_context}] Looking up key: '{key}' - Found: {replacement != f'[{{key}}]'}")  # Debug
                if replacement != f"[{key}]":
                    print(f"      ğŸ”„ Translation: '{key}' -> '{replacement}'")  # Debug
                # æ·»åŠ ç¿»è¯‘åçš„å†…å®¹
                result_parts.append(f"[{replacement}]")
                # æ›´æ–°ä¸‹æ¬¡æœç´¢çš„èµ·å§‹ä½ç½®
                last_end = j
                i = j
            else:
                # æ²¡æ‰¾åˆ°åŒ¹é…çš„ ]ï¼Œå½“ä½œæ™®é€šå­—ç¬¦å¤„ç†
                i += 1
        else:
            i += 1

    # æ·»åŠ æœ€åä¸€éƒ¨åˆ†å†…å®¹
    result_parts.append(text[last_end:])
    return "".join(result_parts)


def apply_translations(entry: dict, trans: Dict[str, str], debug_name: str) -> dict:
    """
    åº”ç”¨ç¿»è¯‘åˆ°æ¡ç›®ï¼Œåªå¯¹ç‰¹å®šå­—æ®µï¼ˆå¦‚ uniquesï¼‰è¿›è¡Œ Translatable å¤„ç†ã€‚
    è¿™æ ·å¯ä»¥é¿å…ä¸å¿…è¦çš„é€’å½’å’Œæ·±åº¦éå†ã€‚
    """
    new_entry = entry.copy()
    if "uniques" in new_entry:
        uniques = new_entry["uniques"]
        if isinstance(uniques, list):
            print(f"  ğŸ“ Processing uniques for {debug_name}")  # Debug
            new_entry["uniques"] = [translate_translatable(u, trans, f"{debug_name}_unique") for u in uniques]
        elif isinstance(uniques, str):
            print(f"  ğŸ“ Processing single unique string for {debug_name}")  # Debug
            new_entry["uniques"] = translate_translatable(uniques, trans, f"{debug_name}_unique")

    if "name" in new_entry and isinstance(new_entry["name"], str):
        print(f"  ğŸ·ï¸  Processing name for {debug_name}")  # Debug
        new_entry["name"] = translate_translatable(new_entry["name"], trans, f"{debug_name}_name")

    if "specialistSlots" in new_entry and isinstance(new_entry["specialistSlots"], dict):
        print(f"  ğŸ§‘â€ğŸ”¬ Processing specialistSlots for {debug_name}")  # Debug
        translated_slots = {}
        for slot_type, stat_key in new_entry["specialistSlots"].items():
            if isinstance(stat_key, str):
                translated_slots[slot_type] = translate_translatable(stat_key, trans, f"{debug_name}_slot_{slot_type}")
            else:
                translated_slots[slot_type] = stat_key  # ä¿æŒåŸå§‹å€¼ï¼ˆå¦‚æœæ˜¯æ•°å­—ç­‰ï¼‰
        new_entry["specialistSlots"] = translated_slots

    return new_entry


def find_image(name: str) -> Path | None:
    """
    æŸ¥æ‰¾æŒ‡å®šåç§°çš„å›¾ç‰‡æ–‡ä»¶ã€‚
    """
    if not name:
        return None
    img_path = IMAGES_DIR / f"{name}.png"
    return img_path.relative_to(MOD_ROOT) if img_path.exists() else None


def main():
    OUTPUT_DIR.mkdir(exist_ok=True)
    PYTHON_DIR.mkdir(exist_ok=True)

    if not JSON_DIR.exists():
        print(f"âŒ 'jsons' ç›®å½•æœªæ‰¾åˆ°", file=sys.stderr)
        sys.exit(1)

    # ä¸‹è½½åŸºç¡€ç¿»è¯‘æ–‡ä»¶
    print("ğŸ” æ­£åœ¨å‡†å¤‡ç¿»è¯‘æ–‡ä»¶...")
    base_trans_dir = PYTHON_DIR / "base_translations"
    base_trans_dir.mkdir(exist_ok=True)
    for lang in LANGUAGES:
        url = f"{BASE_TRANSLATIONS_URL}/{lang}.properties"
        target = base_trans_dir / f"{lang}.properties"
        download_file(url, target)

    # ç”Ÿæˆç»´åŸº
    for lang in LANGUAGES:
        print(f"\nğŸŒ æ­£åœ¨æ„å»º {lang} ç»´åŸº...")
        lang_out = OUTPUT_DIR / lang
        lang_out.mkdir(parents=True, exist_ok=True)

        base_trans = load_properties(base_trans_dir / f"{lang}.properties")
        local_trans_path = JSON_DIR / "translations" / f"{lang}.properties"
        local_trans = load_properties(local_trans_path)
        merged_trans = {**base_trans, **local_trans}

        print(f"ğŸ“Š Total loaded translation keys for {lang}: {len(merged_trans)}")  # Debug

        json_files = list(JSON_DIR.glob("*.json"))
        print(f"ğŸ“ å‘ç° {len(json_files)} ä¸ª JSON æ–‡ä»¶å¾…å¤„ç†...")

        for idx, json_file in enumerate(json_files, 1):
            if json_file.parent.name == "translations":
                continue  # è·³è¿‡ç¿»è¯‘æ–‡ä»¶æœ¬èº«

            print(
                f"  ({idx}/{len([f for f in json_files if f.parent.name != 'translations'])}) æ­£åœ¨å¤„ç†: {json_file.name} ...",
                end='', flush=True)

            try:
                data = load_unciv_json(json_file)
                entries = data if isinstance(data, list) else [data]

                md_lines = [f"# {json_file.stem}\n"]
                for entry_idx, entry in enumerate(entries):
                    if not isinstance(entry, dict) or "name" not in entry:
                        continue

                    # åªå¯¹ç‰¹å®šå­—æ®µåº”ç”¨ç¿»è¯‘
                    debug_entry_name = f"{json_file.stem}_{entry_idx}"
                    translated_entry = apply_translations(entry, merged_trans, debug_entry_name)

                    name = translated_entry["name"]
                    md_lines.append(f"## {name}\n")

                    if img_rel := find_image(entry["name"]):
                        md_lines.append(f"![{name}]({img_rel})\n")

                    # ç±»åˆ«
                    categories = [
                        str(v) for k, v in translated_entry.items()
                        if k.startswith("Class.") and v != "<hidden from users>"
                    ]
                    if categories:
                        md_lines.append(f"**Category**: {', '.join(categories)}\n")

                    # åŸºç¡€å­—æ®µ
                    skip_keys = {"name", "uniques", "specialistSlots"}
                    for k, v in translated_entry.items():
                        if k in skip_keys or k.startswith("Class.") or isinstance(v, (dict, list)):
                            continue
                        md_lines.append(f"- **{k.title()}**: {v}")

                    # ä¸“å®¶æ§½ä½
                    if "specialistSlots" in translated_entry:
                        md_lines.append("\n**Specialist Slots**:")
                        for role, count in translated_entry["specialistSlots"].items():
                            md_lines.append(f"- {role}: {count}")

                    # ç‹¬ç‰¹èƒ½åŠ› - å·²ç”± apply_translations ç¿»è¯‘ï¼
                    if "uniques" in translated_entry and isinstance(translated_entry["uniques"], list):
                        md_lines.append("\n**Unique Abilities**:")
                        for u in translated_entry["uniques"]:
                            md_lines.append(f"- {u}")

                    md_lines.append("\n---\n")

                (lang_out / f"{json_file.stem}.md").write_text("\n".join(md_lines), encoding="utf-8")
                print(" âœ…")  # å¤„ç†å®Œæˆåæ¢è¡Œå¹¶æ˜¾ç¤ºæˆåŠŸæ ‡å¿—

            except Exception as e:
                print(f" âŒ (é”™è¯¯: {e})")  # å¤„ç†å¤±è´¥åæ¢è¡Œå¹¶æ˜¾ç¤ºé”™è¯¯æ ‡å¿—
                # print(f"  âŒ å¤„ç† {json_file} æ—¶å‡ºé”™: {e}", file=sys.stderr) # åŸå§‹é”™è¯¯è¯¦æƒ…

        print(f"âœ… {lang} ç»´åŸºæ„å»ºå®Œæˆï¼")

    # åˆ›å»ºç´¢å¼•é¡µ
    (OUTPUT_DIR / "index.md").write_text(
        "# CoeHarMod Wiki\n\n"
        "- [English](English/)\n"
        "- [ç®€ä½“ä¸­æ–‡](Simplified_Chinese/)\n"
    )
    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼ç»´åŸºå·²ç”Ÿæˆåˆ°: {OUTPUT_DIR}")


if __name__ == "__main__":
    main()