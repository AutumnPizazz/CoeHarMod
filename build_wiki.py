#!/usr/bin/env python3
"""
Mod Wiki Builder for CoeHarMod
Based on Unciv's Civilopedia logic (https://github.com/yairm210/Unciv)
"""
import json
import re
import sys
from pathlib import Path
from typing import Dict, Any, List
from urllib.request import urlopen

# ==================== é…ç½® ====================
MOD_ROOT = Path("python")
JSON_DIR = MOD_ROOT / "jsons"
IMAGES_DIR = MOD_ROOT / "Images"
OUTPUT_DIR = MOD_ROOT / "wiki-output"
BASE_TRANSLATIONS_URL = "https://raw.githubusercontent.com/yairm210/Unciv/master/android/assets/jsons/translations"

LANGUAGES = ["English", "Simplified_Chinese"]


# ==================== å·¥å…·å‡½æ•° ====================

def download_file(url: str, target: Path):
    """å®‰å…¨ä¸‹è½½æ–‡ä»¶"""
    try:
        with urlopen(url) as response, open(target, 'wb') as f:
            f.write(response.read())
        print(f"âœ… Downloaded: {target.name}")
    except Exception as e:
        print(f"âš ï¸ Failed to download {url}: {e}", file=sys.stderr)


def load_properties(file_path: Path) -> Dict[str, str]:
    """åŠ è½½ .properties æ–‡ä»¶"""
    if not file_path.exists():
        return {}
    trans = {}
    with open(file_path, encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith("#") and "=" in line:
                key, value = line.split("=", 1)
                trans[key.strip()] = value.strip().replace("\\n", "\n")
    return trans


def replace_placeholders(text: str, trans: Dict[str, str], depth=0) -> str:
    """é€’å½’æ›¿æ¢ [key] å ä½ç¬¦ï¼ˆæ¨¡ä»¿ Unciv çš„ Translatable.replacePlaceholdersï¼‰"""
    if depth > 5 or not isinstance(text, str):
        return text

    def replace_match(match):
        inner = match.group(1).strip()
        # è·³è¿‡çº¯æ•°å­—ï¼ˆå¦‚ [1]ï¼‰
        if inner.isdigit():
            return match.group(0)
        # é€’å½’ç¿»è¯‘å†…éƒ¨
        translated_inner = replace_placeholders(inner, trans, depth + 1)
        # å°è¯•æ•´ä½“ç¿»è¯‘ï¼ˆå¦‚ "Provides [1] [Resource.Unit.Scientist]"ï¼‰
        full_key = f"[{translated_inner}]"
        if full_key in trans:
            return trans[full_key]
        return f"[{translated_inner}]"

    # å…ˆå¤„ç†æœ€å†…å±‚å ä½ç¬¦
    result = re.sub(r"\$([^]]+)\$", replace_match, text)

    # æœ€åå°è¯•ç¿»è¯‘æ•´ä¸ªå­—ç¬¦ä¸²ï¼ˆUnciv ä¸­å¸¸è§æ¨¡å¼ï¼‰
    if result in trans:
        return trans[result]
    return result


def translate_value(value: Any, trans: Dict[str, str]) -> Any:
    """æ·±åº¦ç¿»è¯‘ä»»æ„å€¼ï¼ˆæ¨¡ä»¿ Unciv çš„ TranslationFileReaderï¼‰"""
    if isinstance(value, str):
        return replace_placeholders(value, trans)
    elif isinstance(value, dict):
        return {k: translate_value(v, trans) for k, v in value.items()}
    elif isinstance(value, list):
        return [translate_value(item, trans) for item in value]
    return value


def find_image(name: str) -> Path | None:
    """ä¸¥æ ¼æŒ‰ name åŒ¹é…å›¾ç‰‡ï¼ˆUnciv å›¾ç‰‡å‘½åè§„åˆ™ï¼‰"""
    if not name:
        return None
    image_path = IMAGES_DIR / f"{name}.png"
    if image_path.exists():
        return image_path.relative_to(MOD_ROOT)
    return None


# ==================== ä¸»æµç¨‹ ====================

def main():
    OUTPUT_DIR.mkdir(exist_ok=True)

    # 1. ä¸‹è½½åŸºç¡€ç¿»è¯‘
    base_trans_dir = MOD_ROOT / "base_translations"
    base_trans_dir.mkdir(exist_ok=True)
    for lang in LANGUAGES:
        url = f"{BASE_TRANSLATIONS_URL}/{lang}.properties"
        target = base_trans_dir / f"{lang}.properties"
        if not target.exists():
            download_file(url, target)

    # 2. ä¸ºæ¯ç§è¯­è¨€ç”Ÿæˆæ–‡æ¡£
    for lang in LANGUAGES:
        print(f"\nğŸŒ Processing language: {lang}")
        lang_output = OUTPUT_DIR / lang
        lang_output.mkdir(parents=True, exist_ok=True)

        # åˆå¹¶ç¿»è¯‘ï¼šæœ¬åœ° > åŸºç¡€
        base_trans = load_properties(base_trans_dir / f"{lang}.properties")
        local_trans = load_properties(JSON_DIR / "translations" / f"{lang}.properties")
        merged_trans = {**base_trans, **local_trans}  # æœ¬åœ°è¦†ç›–åŸºç¡€

        # å¤„ç†æ¯ä¸ª JSON æ–‡ä»¶
        for json_file in JSON_DIR.glob("*.json"):
            if json_file.parent.name == "translations":
                continue

            print(f"  ğŸ“„ {json_file.name}")
            try:
                with open(json_file, encoding="utf-8") as f:
                    entries = json.load(f)

                md_lines = [f"# {json_file.stem}\n"]
                for entry in entries:
                    if not isinstance(entry, dict) or "name" not in entry:
                        continue

                    # æ·±åº¦ç¿»è¯‘æ¡ç›®
                    translated_entry = {
                        k: translate_value(v, merged_trans)
                        for k, v in entry.items()
                    }

                    name = translated_entry["name"]
                    md_lines.append(f"## {name}\n")

                    # æ·»åŠ å›¾ç‰‡
                    if img_rel := find_image(entry.get("name")):
                        md_lines.append(f"![{name}]({img_rel})\n")

                    # æå–åˆ†ç±»ï¼ˆClass.* å­—æ®µï¼‰
                    categories = []
                    for k, v in translated_entry.items():
                        if k.startswith("Class.") and v != "<hidden from users>":
                            categories.append(str(v))
                    if categories:
                        md_lines.append(f"**åˆ†ç±»**: {', '.join(categories)}\n")

                    # åŸºç¡€å­—æ®µï¼ˆè·³è¿‡ç‰¹æ®Šå­—æ®µï¼‰
                    skip_keys = {"name", "uniques", "specialistSlots"}
                    for k, v in translated_entry.items():
                        if k in skip_keys or k.startswith("Class."):
                            continue
                        if isinstance(v, (dict, list)):
                            continue  # å¤æ‚ç»“æ„æš‚ä¸å±•å¼€
                        md_lines.append(f"- **{k.title()}**: {v}")

                    # specialistSlots
                    if "specialistSlots" in translated_entry:
                        md_lines.append("\n**ä¸“å®¶æ§½ä½**:")
                        for role, count in translated_entry["specialistSlots"].items():
                            md_lines.append(f"- {role}: {count}")

                    # uniques
                    if "uniques" in translated_entry and isinstance(translated_entry["uniques"], list):
                        md_lines.append("\n**ç‹¬ç‰¹æ•ˆæœ**:")
                        for u in translated_entry["uniques"]:
                            md_lines.append(f"- {u}")

                    md_lines.append("\n---\n")

                # å†™å…¥æ–‡ä»¶
                output_file = lang_output / f"{json_file.stem}.md"
                output_file.write_text("\n".join(md_lines), encoding="utf-8")

            except Exception as e:
                print(f"  âŒ Error processing {json_file}: {e}", file=sys.stderr)

    # ç”Ÿæˆé¦–é¡µ
    (OUTPUT_DIR / "index.md").write_text(
        "# CoeHarMod ç™¾ç§‘\n\n"
        "- [English](English/)\n"
        "- [ç®€ä½“ä¸­æ–‡](Simplified_Chinese/)\n"
    )
    print(f"\nğŸ‰ Wiki generated at: {OUTPUT_DIR}")


if __name__ == "__main__":
    main()